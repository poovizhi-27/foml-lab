{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import log, dot, exp, shape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/suv_data.csv')\n",
        "print(data.head())\n",
        "\n",
        "# Features and target\n",
        "x = data.iloc[:, [2, 3]].values  # Age, EstimatedSalary\n",
        "y = data.iloc[:, 4].values       # Purchased\n",
        "\n",
        "# -------------------- In-built Logistic Regression --------------------\n",
        "# Split and scale\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=0)\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "# Train\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = classifier.predict(x_test)\n",
        "print(\"Predictions:\", y_pred)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------- User-defined Logistic Regression --------------------\n",
        "# Split again (if needed)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=0)\n",
        "\n",
        "# Standardization helper\n",
        "def standardize(X_tr):\n",
        "    for i in range(shape(X_tr)[1]):\n",
        "        X_tr[:, i] = (X_tr[:, i] - np.mean(X_tr[:, i])) / np.std(X_tr[:, i])\n",
        "\n",
        "# F1-score function\n",
        "def F1_score(y, y_hat):\n",
        "    tp = tn = fp = fn = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1 and y_hat[i] == 1:\n",
        "            tp += 1\n",
        "        elif y[i] == 1 and y_hat[i] == 0:\n",
        "            fn += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 1:\n",
        "            fp += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 0:\n",
        "            tn += 1\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "    return f1_score\n",
        "\n",
        "# Logistic Regression class\n",
        "class LogisticRegressionCustom:\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + exp(-z))\n",
        "\n",
        "    def initialize(self, X):\n",
        "        weights = np.zeros((shape(X)[1] + 1, 1))\n",
        "        X = np.c_[np.ones((shape(X)[0], 1)), X]\n",
        "        return weights, X\n",
        "\n",
        "    def fit(self, X, y, alpha=0.001, iter=400):\n",
        "        weights, X = self.initialize(X)\n",
        "        y = y.reshape(-1, 1)\n",
        "\n",
        "        def cost(theta):\n",
        "            z = dot(X, theta)\n",
        "            cost0 = y.T.dot(log(self.sigmoid(z)))\n",
        "            cost1 = (1 - y).T.dot(log(1 - self.sigmoid(z)))\n",
        "            return -((cost1 + cost0)) / len(y)\n",
        "\n",
        "        cost_list = np.zeros(iter)\n",
        "        for i in range(iter):\n",
        "            z = dot(X, weights)\n",
        "            h = self.sigmoid(z)\n",
        "            weights -= alpha * dot(X.T, h - y)\n",
        "            cost_list[i] = cost(weights)\n",
        "        self.weights = weights\n",
        "        return cost_list\n",
        "\n",
        "    def predict(self, X):\n",
        "        _, X = self.initialize(X)\n",
        "        z = dot(X, self.weights)\n",
        "        preds = self.sigmoid(z)\n",
        "        return [1 if i > 0.5 else 0 for i in preds]\n",
        "\n",
        "# Apply standardization\n",
        "standardize(x_train)\n",
        "standardize(x_test)\n",
        "\n",
        "# Train and predict\n",
        "obj = LogisticRegressionCustom()\n",
        "model = obj.fit(x_train, y_train)\n",
        "y_pred_custom = obj.predict(x_test)\n",
        "y_train_pred = obj.predict(x_train)\n",
        "\n",
        "# Evaluate\n",
        "f1_score_train = F1_score(y_train, y_train_pred)\n",
        "f1_score_test = F1_score(y_test, y_pred_custom)\n",
        "\n",
        "print(\"F1 Score (Train):\", f1_score_train)\n",
        "print(\"F1 Score (Test):\", f1_score_test)"
      ],
      "metadata": {
        "id": "I6Ocn2cbk7N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWSy6dP9kuYR"
      },
      "outputs": [],
      "source": []
    }
  ]
}